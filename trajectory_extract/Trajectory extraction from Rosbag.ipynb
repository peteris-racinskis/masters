{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "873531db",
   "metadata": {},
   "source": [
    "# Trajectory extraction from Rosbag file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c8723a",
   "metadata": {},
   "source": [
    "The goal of this script is to take a raw rosbag recording of a scene and partition out a set of discrete throw demonstrations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed92ff1",
   "metadata": {},
   "source": [
    "## Raw rosbag conversion to csv with time-series position data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa849d58",
   "metadata": {},
   "source": [
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6c0e786",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bagpy import bagreader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb354ce",
   "metadata": {},
   "source": [
    "Constants - file paths, topic handles and other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e9f173",
   "metadata": {},
   "outputs": [],
   "source": [
    "IFILE=\"rawdata/record_all_demonstrations.bag\"\n",
    "OFILE=\"processed_data/combined_timeseries.csv\"\n",
    "BOTTLE=\"/mocap_node/Bottle/Odom\"\n",
    "CATCHER=\"/mocap_node/CatchNet/Odom\"\n",
    "GRIPPER=\"/mocap_node/TrashPickup/Odom\"\n",
    "NAME_INDEX = 2\n",
    "TIME=\"Time\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaf17b2",
   "metadata": {},
   "source": [
    "Odometry extraction from a topic csv file. There is a large number of superfluous columns that can be discarded early on. To make merging the odometry time series of different objects possible it's necessary to rename the coordinate columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1b2271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def odom_extract(df: pd.DataFrame, name: str) -> pd.DataFrame:\n",
    "    relevant = [\n",
    "        \"Time\",\n",
    "        \"pose.pose.position.x\",\n",
    "        \"pose.pose.position.y\",\n",
    "        \"pose.pose.position.z\",\n",
    "        \"pose.pose.orientation.x\",\n",
    "        \"pose.pose.orientation.y\",\n",
    "        \"pose.pose.orientation.z\",\n",
    "        \"pose.pose.orientation.w\",\n",
    "    ]\n",
    "    name_map = {s:s.replace(\"pose.pose\",name) for s in relevant[1:]}\n",
    "    out = df[relevant]\n",
    "    return out.rename(columns=name_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364aeccc",
   "metadata": {},
   "source": [
    "Convenience functions for reading each topic and merging them all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7e155c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_read(topic: str, bg: bagreader) -> pd.DataFrame:\n",
    "    name = topic.split(\"/\")[NAME_INDEX]\n",
    "    topic_csv = bg.message_by_topic(topic)\n",
    "    topic_df = odom_extract(pd.read_csv(topic_csv), name)\n",
    "    return topic_df\n",
    "\n",
    "def df_merge(*dfs) -> pd.DataFrame:\n",
    "    combined = pd.concat(dfs)\n",
    "    return combined.sort_values(by=[TIME])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f99913",
   "metadata": {},
   "source": [
    "Putting it all together, execution (takes a while because the rosbag recordings are large files):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df529a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = bagreader(IFILE)\n",
    "bottle = topic_read(BOTTLE, ds)\n",
    "catch_net = topic_read(CATCHER, ds)\n",
    "gripper = topic_read(GRIPPER, ds)\n",
    "output = df_merge(bottle, catch_net, gripper)\n",
    "output.to_csv(OFILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613b5835",
   "metadata": {},
   "source": [
    "## Position interpolation, shared argument axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46896bc4",
   "metadata": {},
   "source": [
    "Fill all the missing values and produce regularly spaced timestamp values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65507b6",
   "metadata": {},
   "source": [
    "Imports and constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95b91e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmath import nan\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "IFILE=\"processed_data/combined_timeseries.csv\"\n",
    "OFILE=\"processed_data/regular_timeseries.csv\"\n",
    "TIME=\"Time\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8a9042",
   "metadata": {},
   "source": [
    "Resampling code - produce a dataframe with regularly spaced timestamps, initially filled wiht NaN values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6da633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_float(f, step):\n",
    "    inv = 1 / step\n",
    "    return float((int(f * inv) + 1)) / inv\n",
    "\n",
    "def resample(df: pd.DataFrame, step=0.01) -> Tuple[pd.DataFrame, np.ndarray]:\n",
    "    start = trim_float(df.iloc[0][TIME], step)\n",
    "    end = trim_float(df.iloc[-1][TIME], step)\n",
    "    times = np.arange(start=start, stop=end, step=step)\n",
    "    d={\"Time\": times, \"Unnamed: 0\": \"Not a number\"}\n",
    "    cols = df.columns\n",
    "    regular = pd.DataFrame(data=d, columns=cols)\n",
    "    return regular, times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca44f09e",
   "metadata": {},
   "source": [
    "\"Interpolate\" - actually just forward fill the missing values (for now):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d073347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(df: pd.DataFrame, reg: pd.DataFrame) -> pd.DataFrame:\n",
    "    combined = pd.concat([df, reg])\n",
    "    combined: pd.DataFrame = combined.drop_duplicates(subset=[TIME]).sort_values(by=[TIME])\n",
    "    interp = combined.fillna(method=\"ffill\")\n",
    "    return interp.loc[lambda d: d[\"Unnamed: 0\"] == \"Not a number\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92401102",
   "metadata": {},
   "source": [
    "Execution code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5a7ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(IFILE)\n",
    "rows, index = resample(df)\n",
    "interpolated = interpolate(df, rows)\n",
    "interpolated.to_csv(OFILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9225952",
   "metadata": {},
   "source": [
    "## Throw separation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf52281",
   "metadata": {},
   "source": [
    "Here each throw is separated out into a different dataframe and the intervening data are discarded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20685d9",
   "metadata": {},
   "source": [
    "Imports and constants. This time there's a need to rename columns that would get duplicated, various panda DataFrame operations like max() and diff() keep the name of whatever column they were applied along in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b8f2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import times\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from typing import List\n",
    "IFILE=\"processed_data/regular_timeseries.csv\"\n",
    "OFILE_BASE=\"processed_data/demo-\"\n",
    "TIME=\"Time\"\n",
    "GRIPPER_X=\"TrashPickup.position.x\"\n",
    "GRIPPER_XLIMU=\"TrashPickup.position.xlim+\"\n",
    "GRIPPER_XLIML=\"TrashPickup.position.xlim-\"\n",
    "BOTTLE_X=\"Bottle.position.x\"\n",
    "BOTTLE_XLIMU=\"Bottle.position.xlim+\"\n",
    "BOTTLE_XLIML=\"Bottle.position.xlim-\"\n",
    "WINDOW=150\n",
    "STEPS=500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddb4c4e",
   "metadata": {},
   "source": [
    "This function finds the starting index of each throw demonstration. First, rolling maxima and minima are computed for the entire dataframe. Then the combined dataframe is checked against upper and lower limits found by visually inspecting the trajectories in PlotJuggler. Finally, the thresholded points are diffed - only ones more than 5 seconds after the preceding data point are considered starting indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fff7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_starts(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    upper = df.rolling(150).max()[[GRIPPER_X, BOTTLE_X]].rename(columns={GRIPPER_X:GRIPPER_XLIMU, BOTTLE_X:BOTTLE_XLIMU})\n",
    "    lower = df.rolling(150).min()[[GRIPPER_X, BOTTLE_X]].rename(columns={GRIPPER_X:GRIPPER_XLIML, BOTTLE_X:BOTTLE_XLIML})\n",
    "    combined = pd.concat([df, upper, lower], axis=1)\n",
    "    starts = combined.loc[lambda d: (d[GRIPPER_XLIMU] <= 1.2) &\n",
    "                                    (d[GRIPPER_XLIML] >= 1.1) &\n",
    "                                    (d[BOTTLE_XLIMU] <= 1.2) &\n",
    "                                    (d[BOTTLE_XLIML] >= 1.1)]\n",
    "    diffs = starts[TIME].diff()\n",
    "    return diffs.loc[lambda d: d > 5].index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246689de",
   "metadata": {},
   "source": [
    "This helper function produces a STEPS timestep long dataframe for each starting index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5753c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subframes(df: pd.DataFrame, indices) -> List[pd.DataFrame]:\n",
    "    dfs = []\n",
    "    for index in indices:\n",
    "        dfs.append(df.iloc[index:index+STEPS])\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c35afc",
   "metadata": {},
   "source": [
    "But this one converts the timestamp of the first observation to a datetime string, creates a filename and outputs the dataframe to a csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eace18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_and_write(df: pd.DataFrame):\n",
    "    t = df.iloc[0][TIME]\n",
    "    timestamp = datetime.utcfromtimestamp(t).strftime('%d-%m-%Y-%H:%M:%S')\n",
    "    fname = f\"{OFILE_BASE}{timestamp}.csv\"\n",
    "    df.to_csv(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d315d9",
   "metadata": {},
   "source": [
    "## Gripper separation event detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1ef465",
   "metadata": {},
   "source": [
    "The goal of this section is to produce a timestamp for when the gripper and bottle have separated, for each demonstration trajectory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
